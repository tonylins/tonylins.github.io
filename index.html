<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Ji Lin's Homepage</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <link rel="stylesheet" href="stylesheets/bootstrap.min.css">
    <link rel="stylesheet" href="stylesheets/font-awesome.min.css">
    
    <meta name="viewport" content="width=device-width">
    
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <br />
        <div align="center">
            <span class="image avatar" >
    		  <img src="images/avatar.jpg" ></img>
            </span>
        </div>
        <h1><b>Ji (Tony) Lin</b></h1>

        <p> 
            <a href="https://www.linkedin.com/in/ji-lin-1552bba7/"><font color="#222"><i class="fa fa-linkedin fa-2x"></i></font></a> &nbsp &nbsp
            <a href="https://github.com/tonylins"><font color="#222"><i class="fa fa-github fa-2x"></i> </font></a> &nbsp  &nbsp 
            <a href="https://www.instagram.com/__tonylin/"><font color="#222"><i class="fa fa-instagram fa-2x"></i> </font></a> &nbsp &nbsp

            <span class="cv_right">
                <a href="files/Ji_Lin_CV.pdf"><font size="4em" color="#222">Curriculum Vitae</font></a>
            </span>
        </p>
        <br />

        <h4>Contact:</h4>
        <p>
            <font face="courier">to.tonylin AT gmail.com </font>
        </p>

        
      </header>


      <section>
            <!-- About Me -->
    	    <h2>About Me</h2>
    			<p>I am currently a senior undergraduate student in <a href="http://www.ee.tsinghua.edu.cn/publish/eeen/index.html"><font color="3498DB">Department of Electronic Engineering</font></a>, <a href="http://www.sist.tsinghua.edu.cn/docinfo_eng/index.jsp"><font color="3498DB">School of Information Science and Technology</font></a>, <a href="http://www.tsinghua.edu.cn/publish/newthuen/index.html"><font color="3498DB">Tsinghua University</font></a>. My Chinese name is 林己 <a href="http://tts.imtranslator.net/ajip"><font color="3498DB">[pronounce]</font></a>.</p>

                <p>
                    I worked in <a href="http://ivg.au.tsinghua.edu.cn/index.php"><font color="3498DB">Intelligent Vision Group (IVG)</font></a>, advised by Prof. <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/"><font color="3498DB">Jiwen Lu</font></a> since Fall 2016. 
                    In Spring 2015, I worked in <a href="https://nicsefc.ee.tsinghua.edu.cn"><font color="3498DB">Energy Efficient Computing Group</font></a>, advised by Prof. <a href="https://nicsefc.ee.tsinghua.edu.cn/people/yu-wang/"><font color="3498DB">Yu Wang</font></a>. 
                    In Summer 2017, I worked at <a href="http://http://bair.berkeley.edu/" target=_blank><font color="3498DB">Berkeley Artificial Intelligence Research (BAIR)</font></a> as a research assistant, advised by Prof. <a href="http://www.eecs.berkeley.edu/~trevor/" target=_blank><font color="3498DB">Trevor Darrell</font></a>, Prof. <a href="https://people.eecs.berkeley.edu/~svlevine/" target=_blank><font color="3498DB">Sergey Levine</font></a> and Dr. <a href="http://www.yf.io/" target=_blank><font color="3498DB">Fisher Yu</font></a>.
                </p>
                <p>My research interests lie in computer vision, deep learning, reinforcement learning and their applications.</p>

            <!-- Education -->
            <h2>Education</h2>
    		
            <div class="media">
                <span class="pull-left"><img src="./images/tsinghua.png" width="96px" height="96px"/></span>
                <div class="media-body">
                    <p><span style="font-weight: bold">Aug. 2014 - Jul. 2018 (Expected)</span>, Department of Electronic Engineering, <i><b>Tsinghua University</b></i>,</p>
                    <p>Balchlor of Engineering, <b>GPA: 91/100</b>.</p>
                </div>  
            </div>

            <div class="media">
                <span class="pull-left"><img src="./images/berkeley.png" width="96px" height="96px"/></span>
                <div class="media-body">
                    <p><span style="font-weight: bold">Jun. 2017 - Sept. 2017</span>, Department of Electrical Engineering and Computer Sciences, <i><b>University of California, Berkeley</b></i>,</p>
                    <p>Visiting Researcher.</p>
                </div>
            </div>

            <!-- Publications -->
            <h2>Publications</h2>
            <ul>
                <li><b>J. Lin</b>, Y. Rao, J. Lu, Runtime Neural Pruning,
                <i>to appear in NIPS 2017</i>.</li> 
                <li>Y. Rao, <b>J. Lin</b>, J. Lu, Learning Discriminative Aggregation Network for Video Face Recognition, <i>in ICCV 2017 (spotlight)</i>. &nbsp <a href="#"><font color="3498DB">[pdf]</font></a></li>  
                <li><b>J. Lin</b>, L. Ren, J. Lu, J. Feng, J. Zhou. Consistent-aware Deep Learning for Person Re-identification in a Camera Network, <i>in CVPR 2017 (spotlight).</i> &nbsp <a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Lin_Consistent-Aware_Deep_Learning_CVPR_2017_paper.pdf"><font color="3498DB">[pdf]</font></a></li>
            </ul>
                  
            <!-- Research -->
            <h2>Selected Research Projects</h2>
    		
            <div class="media">
                <span class="pull-left"><br /><a href="images/3D_vehicle.jpg" class="image"><img src="images/3D_vehicle.jpg" width="96px" height="54" alt="" /></a></span>
                <div class="media-body">
    				<p><b>3D Vehicle Extent and Future Trajectory Prediction</b>,</p>
    				<p>Ji Lin, Dequan Wang, Fisher Yu, Trevor Darrell,</p>
                    <p>Jul 2017 - Nov 2017, <i><b>UC Berkeley</b></i>,</p>
                    <p>To properly control and plan for a self-driving vehicle, we need to expect how the other vehicles will drive in the future. While real-world data are expensive to annotate, we hack GTA V as a simulator to collect a large-scale dataset of visual observation and annotation. Given sequence of images we perform 3D vehicle bounding box detection, tracking, and future trajectory prediction. Further we show that model trained on synthetic data is applicable to real-world data like KITTI.</p>
                </div>
            </div>

           <div class="media">
                <span class="pull-left"><br /><a href="images/demo_rl.jpg" class="image"><img src="images/demo_rl.jpg" width="96px" alt="" /></a></span>
                <div class="media-body">
    				<p><b>Learning from Human Demonstration and Self-exploration for Faster Reinforcement Learning</b>,</p>
    				<p>Yang Gao, Huazhe Xu, Ji Lin, Fisher Yu, Sergey Levine, Trevor Darrell,</p>
                    <p>Jul 2017 - Oct 2017, <i><b>UC Berkeley</b></i>,</p>
                    <p>We design a unified framework based on Soft Q-Learning and Policy Gradient that jointly learns from human demonstration and in environment exploration. Our algorithm can switch smoothly from demonstration to environment exploration with no performance loss. Further, our method is able to handle noisy demonstration and multi-modality data, which is not feasible with supervised methods. We test our method on Enduro, TORCS and GTA V to show its effectiveness in driving tasks.</p>
                </div>
            </div>

    		<div class="media">
                <span class="pull-left"><br /><a href="images/rnp.png" class="image"><img src="images/rnp.png" width="96px" alt="" /></a></span>
                <div class="media-body">
    				<p><b>Dynamical Network Pruning with Reinforcement Learning</b>,</p>
    				<p>Ji Lin, Yongming Rao, Jiwen Lu,</p>
                    <p>Mar 2017 - May 2017, <i><b>Tsinghua University</b></i>,</p>
                    <p>We develop an algorithm to dynamically prune the neural network according to the difficulty of input image at runtime, which is scalable to existing neural network structures. We model the pruning as a bottom-up, layer-by-layer MDP, solved by reinforcement learning, and address the problem of large action space and long trajectory. Our method achieves much better spped-accuracy tradeoff on CIFAR and ImageNet, proving the effectiveness of sample specific inference. </p>
                </div>
            </div>

            <div class="media">
                <span class="pull-left"><br /><a href="images/facegan.png" class="image"><img src="images/facegan.png" width="96px" alt="" /></a></span>
                <div class="media-body">
                    <p><b>Combine Adversarial Learning and Metric Learning for Efficient Aggregation Network</b>,</p>
                    <p>Yongming Rao, Ji Lin, Jiwen Lu,</p>
                    <p>Jan 2017 - Apr 2017, <i><b>Tsinghua University</b></i>,</p>
                    <p>We develop an aggregation method that produces single high-quality image from redundant and noisy face videos. By combining adversarial learning and metric learning we make the generated image realistic and discriminative in the feature space, which speeds up the recognition greatly and improves accuracy. </p>
                </div>
            </div>
    		
            <div class="media">
                <span class="pull-left"><br /><a href="images/cadl.png" class="image"><img src="images/cadl.png" width="96px" alt="" /></a></span>
                <div class="media-body">
                    <p><b>Consistent-aware Deep Person Re-identification in a Camera Network</b>,</p>
                    <p>Ji Lin, Liangliang Ren, Jiwen Lu, Jianjiang Feng, Jie Zhou,</p>
                    <p>June 2016 - Nov 2016, <i><b>Tsinghua University</b></i>,</p>
                    <p>We develop one of the first frameworks to address the inconsistency problem in multi-camera person re-identification. We model multi-camera re-identification as an optimization problem and solved with gradient descent to eliminate inconsistency, which also guides the back-propagation in the training phase. Our methods outperforms state-of-the-arts by large margins on multiple datasets. </p>
                </div>
            </div>
            
            <!-- Work -->
            <h2>Work Experience</h2>
            <ul>
                <li><strong><a href="https://www.sensetime.com/"><font color="3498DB">SenseTime Group Limited</font></a></strong> 
                    <br> <b>Vision Researcher, Detection Team </b>
                    <br> Jan 2017 - Mar 2017, Beijing, China
                    <br>Developed algorithm on semi-supervised face detection, and more efficient training with large scale dataset. Explored efficient models for object detection. Part of the results were deployed in real products.</br> </li>
            </ul>

    	
    		<!-- Honors -->
            <section id="Honors">
                <h2>Honors and Awards</h2>
        		<h4>Academic</h4>
                    <ul>
                        <li><strong>Invited presentation at <a href="http://bigeye.au.tsinghua.edu.cn/sidas2017/index.html"><font color="3498DB">IEEE SIDAS 2017</font></a></strong> &nbsp 2017
                    </ul>
                <h4>Fellowships</h4>
                    <ul>
                        <li><strong>Fellowship of <a href="http://www.tuef.tsinghua.edu.cn/column/sp1"><font color="3498DB">Spark Talents Program</font></a></strong> &nbsp 2016
                            <br>Awarded to the top 50 Tsinghua students, dedicated to scientific and technological innovations</br> </li>
                    </ul>
                <h4>Scholarships</h4>
                    <ul>
                        <li><strong>Annual Academic Excellent Award</strong> &nbsp 2015-2017
                            <br>Awarded to students with excellent academic achievements, top ~5% out of 262 students.</br> </li>
                        <li><strong>Annual Comprehensive Excellent Award</strong> &nbsp 2015-2017
                            <br>Awarded to students with excellent comprehensive performance, top ~5% out of 262 students.</br> </li>
                        <li><strong>Scholarship of Freshmen, Tsinghua University</strong> &nbsp 2014
                            <br>Awarded to top 10 students in College Entrance Exam.</br> </li>
                    </ul>
                <h4>Awards</h4>
                    <ul>
                        <li><strong>3<sup>nd</sup> Prize of IEEE 2016 Low Power Image Recognition Challenge (LPIRC’16)</strong> &nbsp 2016
                            <br>Aim to discover the best technology in both image recognition and energy conservation</br> </li>
                        <li><strong>1<sup>st</sup> Prize of 17<sup>th</sup> Electronic Design Contest, Tsinghua University</strong> &nbsp 2016
                            <br>Top robotics competition in Tsinghua University. Rank No.1 in 400 entrants. </br> </li>
                        <!-- <li><strong>2<sup>nd</sup> Prize in the National Chemistry Olympiad </strong> &nbsp 2013</li>  -->
                    </ul>
            </section>

            <section id="Skills">
                <h2>Skills</h2>
                <ul>
                <br><i class="fa fa-code fa-2x fa-fw"></i> &nbsp Python &nbsp C/C++ &nbsp MATLAB &nbsp Java &nbsp Android <br />
                <br><i class="fa fa-wrench fa-2x fa-fw"></i> &nbsp LaTeX &nbsp Caffe &nbsp TensorFlow &nbsp PyTorch <br />
                <br><i class="fa fa-language fa-2x fa-fw"></i> &nbsp Mandarin Chinese (native) &nbsp English (proficiet)
                </ul>
            </section>

            <!-- Life -->
            <section id="Life">
            	<h2>Life :)</h2>
                    Here is a partial catalog of my attempts at becoming more than what I am today. I doubt I will ever succeed totally but I hope I will never stop trying.
                    <p></p>
                    <h4>Photography</h4>
                    <p> I've been long interested in photography for more than two years. Since I bought my first camera in Spring 2015, I've learnt so much in Photography Team of Tsinghua Student Art Troupe. I catch the sparkling moments and beauties in my life with my camera as very precious memories. I do not post too much of my work on the Internet, but you can still find some in the following sites: <br />
                        <font color="3498DB">
                        <a href="https://www.instagram.com/__tonylin/">[Instagram]</a> &nbsp 
                        <a href="https://500px.com/to_tonylin"> [500PX] </a> &nbsp 
                        <a href="https://tuchong.com/519520/"> [TuChong] </a> &nbsp 
                    </font>

                    <h4>Piano</h4>
                    <p> I've always wanted to pick up some kind of musical instruments. It may not be the proper age to be proficient in piano, but I'll keep trying. <br />

                    <h4>Tennis</h4>
                    <p> Tennis is my recent favorite sport (still not proficient though). Reach me if you are interested too! <br />

            </section>
        	
          	<h2>Who searched for me!</h2>
            <div id="clustrmaps-widget">
    		  <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=oQ1KwKMwMu6IYuA5fNffQwoGDCui7FZHrx3Dd2G8VDM&cl=ffffff&w=a"></script>
            </div>
            
        </section>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
