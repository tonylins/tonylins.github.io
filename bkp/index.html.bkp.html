<!doctype html>
<html>
  <head>
    <!-- Global Site Tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-106869316-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments)};
      gtag('js', new Date());

      gtag('config', 'UA-106869316-1');
    </script>


    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Ji Lin's Homepage</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <link rel="stylesheet" href="stylesheets/bootstrap.min.css">
    <link rel="stylesheet" href="stylesheets/font-awesome.min.css">

    <link rel="stylesheet" href="stylesheets/special.css">

    
    <meta name="viewport" content="width=device-width">
    
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

  </head>
  <body>
    <div class="wrapper">
      <header>
        <br />
        <div align="center">
            <span class="image avatar" >
    		  <img src="images/avatar.jpg" ></img>
            </span>
        </div>
        <h1><b>Ji (Tony) Lin</b></h1>

        <p> 
            <a href="https://www.linkedin.com/in/ji-lin-1552bba7/"><font color="#222"><i class="fa fa-linkedin fa-2x"></i></font></a> &nbsp &nbsp
            <a href="https://github.com/tonylins"><font color="#222"><i class="fa fa-github fa-2x"></i> </font></a> &nbsp  &nbsp 
            <a href="https://www.instagram.com/__tonylin/"><font color="#222"><i class="fa fa-instagram fa-2x"></i> </font></a> &nbsp &nbsp

            <span class="cv_right">
                <a href="files/Ji_Lin_CV.pdf"><font size="4em" color="#222"><b>[CV]</b></font></a>
            </span>
        </p>
        <br />

        <h4>Contact:</h4>
        <p>
            <font face="courier">to.tonylin AT gmail.com </font>
        </p>

        
      </header>


      <section class="outer">
      		<!-- About Me -->
      		<section  id="about">
	    	    <h2>About Me</h2>
	    			<p>I am currently a senior undergraduate student in <a href="http://www.ee.tsinghua.edu.cn/publish/eeen/index.html">Department of Electronic Engineering</a>, <a href="http://www.sist.tsinghua.edu.cn/docinfo_eng/index.jsp">School of Information Science and Technology</a>, <a href="http://www.tsinghua.edu.cn/publish/newthuen/index.html">Tsinghua University</a>. My Chinese name is 林己 <a href="http://tts.imtranslator.net/ajip">[pronounce]</a>.</p>

	                <p>
	                    I worked in <a href="http://ivg.au.tsinghua.edu.cn/index.php">Intelligent Vision Group (IVG)</a>, advised by Prof. <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/">Jiwen Lu</a> since Fall 2016. 
	                    In Spring 2015, I worked in <a href="https://nicsefc.ee.tsinghua.edu.cn">Energy Efficient Computing Group</a>, advised by Prof. <a href="https://nicsefc.ee.tsinghua.edu.cn/people/yu-wang/">Yu Wang</a>. 
	                    <!-- In Summer & Fall 2017, I worked at <a href="http://http://bair.berkeley.edu/" target=_blank>Berkeley Artificial Intelligence Research (BAIR)</a> as a research assistant.  --> I am currently visting at MIT EECS, advised by Prof. <a href="https://stanford.edu/~songhan/">Song Han</a>.
	                </p>
	                <p>My research interests lie in machine learning, efficinet deep learning, computer architecture and their applications.</p>
			</section>
			
			<!-- Education -->
			<section  id="education">
	            <h2>Education</h2>

	            <div class="media">
	                <span class="pull-left"><img src="./images/tsinghua.png" width="96px" height="96px"/></span>
	                <div class="media-body">
	                    <p><span style="font-weight: bold">Aug. 2014 - June 2018 (Expected)</span>, Department of Electronic Engineering, <i><b>Tsinghua University</b></i>,</p>
	                    <p>Bachelor of Engineering.</p>
	                </div>  
	            </div>
<!--
	            <div class="media">
	                <span class="pull-left"><img src="./images/berkeley.png" width="96px" height="96px"/></span>
	                <div class="media-body">
	                    <p><span style="font-weight: bold">June 2017 - Nov. 2017</span>, Department of Electrical Engineering and Computer Sciences, <i><b>University of California, Berkeley</b></i>,</p>
	                    <p>Visiting Researcher.</p>
	                </div>
	            </div>
-->
        	</section>
			
			<!-- Publications -->
			<section  id="publication">
	            <h2>Publications</h2>
	            <ol>
                    <li>T. Chen, <b>J. Lin</b>, T. Lin, C. Wang, D. Zhou, S. Han, Adaptive Mixture of Low-Rank Factorizations for Compact Neural Modeling, <i>submitted to NIPS 2018</i>. &nbsp </li> 
                    <li>Y. He, <b>J. Lin</b>, S. Han, AMC: Automatic Model Compression and Acceleration with Reinforcement Learning, <i>submitted to ECCV 2018</i>. &nbsp </li> 
                    <li>Y. Rao, <b>J. Lin</b>, B. Liu, J. Lu, SkeletonCNN: Affine-invariant feature learning for skeleton-based human analysis, <i>submitted to ECCV 2018</i>. &nbsp [pdf][code] </li> 
                    <!-- <li><b>J. Lin</b>, D. Wang, D. Zhang, P. Krahenbuhl, T. Darrell, F. Yu, Joint Monocular 3D Vehicle Detection and Tracking, <i>submitted to ECCV 2018</i>. &nbsp </li>  -->
                    <!-- <li>Y. Gao*, H. Xu*, <b>J. Lin</b>, F. Yu, S. Levine, T. Darrell, Reinforcement Learning from Imperfect Demonstrations,
                    <i>in ICLR 2018 Workshop / submitted to ICML 2018</i>. &nbsp <a href="https://arxiv.org/pdf/1802.05313.pdf">[pdf]</a></li> -->
                    <li>Y. Rao, <b>J. Lin</b>, J. Lu, J. Zhou, Runtime network routing for efficient image classification, <i>submitted to T-PAMI, 2018</i>. </li> 
	                <li><b>J. Lin</b>*, Y. Rao*, J. Lu, J. Zhou, Runtime Neural Pruning,
	                <i>in NIPS 2017</i>. &nbsp <a href="https://papers.nips.cc/paper/6813-runtime-neural-pruning.pdf">[pdf]</a></li> 
	                <li>Y. Rao, <b>J. Lin</b>, J. Lu, J. Zhou, Learning Discriminative Aggregation Network for Video-Based Face Recognition, <i>in ICCV 2017 (<u>spotlight</u>) </i>. &nbsp <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Rao_Learning_Discriminative_Aggregation_ICCV_2017_paper.pdf">[pdf]</a>
                        <a href="files/DAN_supplementary.pdf">[sup]</a></li>  
	                <li><b>J. Lin</b>, L. Ren, J. Lu, J. Feng, J. Zhou. Consistent-aware Deep Learning for Person Re-identification in a Camera Network, <i>in CVPR 2017 (<u>spotlight</u>).</i> &nbsp <a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Lin_Consistent-Aware_Deep_Learning_CVPR_2017_paper.pdf">[pdf]</a>
                        <a href="files/CADL_supplementary.pdf">[sup]</a></li>
	            </ol>
        	</section>
                  
            <!-- Research -->
            <section  id="research">
	            <h2>Selected Publications</h2>
	    		
                <!-- <div class="media">
                    <span class="pull-left"><br /><a href="images/iclr_fig.png" class="image"><img src="images/iclr_fig.png" width="96px" alt="" /></a></span>
                    <div class="media-body">
                        <p><b>Learning from Imperfect Demonstrations with Reinforcement Learning</b>,</p>
                        <p>Yang Gao, Huazhe Xu, Ji Lin, Fisher Yu, Sergey Levine, Trevor Darrell,</p>
                        <p>Jul 2017 - Feb 2018, <i><b>UC Berkeley</b></i>,</p>
                        <p>We design a unified framework based on soft Q-Learning and policy gradient that jointly learns from human demonstration and in environment exploration. Our algorithm can switch smoothly from demonstration to environment exploration with no performance loss. Further, our method is able to handle noisy demonstration data, which is not feasible with supervised methods. We test our method in TORCS and GTA V to show its effectiveness in driving tasks.</p>
                    </div>
                </div> -->
<!--
	            <div class="media">
	                <span class="pull-left"><br /><a href="images/3D_vehicle.jpg" class="image"><img src="images/3D_vehicle.jpg" width="96px" height="54" alt="" /></a></span>
	                <div class="media-body">
	    				<p><b>Deep 3D Vehicle Tracking with Synthetic Dataset</b>,</p>
	    				<p>Ji Lin, Dequan Wang, David Zhang, Philipp Krahenbuhl, Fisher Yu, Trevor Darrell,</p>
	                    <p>Jul 2017 - Nov 2017, <i><b>UC Berkeley</b></i>,</p>
	                    <p>We develop a novel method using a region-based recurrent tracking architecture that can obtain accurate 3D trajectories of moving vehicles from monocular dash cam videos. While real-world data are expensive to annotate, we hack the GTA V game as a simulator for autonomous driving and collect a new large-scale dataset of visual observation and rich annotations, including 2D/3D bounding box, geo-information, tracking ID, etc.
                        </p>
	                </div>
	            </div>
-->

	    		<div class="media">
	                <span class="pull-left"><br /><a href="images/rnp.png" class="image"><img src="images/rnp.png" width="96px" alt="" /></a></span>
	                <div class="media-body">
	    				<p><b>Dynamical Network Pruning with Reinforcement Learning</b>,</p>
	    				<p>Ji Lin, Yongming Rao, Jiwen Lu, Jie Zhou,</p>
	                    <p>Mar 2017 - May 2017, <i><b>Tsinghua University</b></i>,</p>
	                    <p>We develop a method to dynamically prune the neural network according to the difficulty of an input image at runtime, scalable to existing neural network structures. We model the pruning as a bottom-up, layer-by-layer MDP, solved by reinforcement learning, and address the problem of large action space and long trajectory. Our method achieves much better speed-accuracy tradeoff on CIFAR and ImageNet, proving the effectiveness of sample-specific inference. </p>
	                </div>
	            </div>

	            <div class="media">
	                <span class="pull-left"><br /><a href="images/facegan.png" class="image"><img src="images/facegan.png" width="96px" alt="" /></a></span>
	                <div class="media-body">
	                    <p><b>Combine Adversarial Learning and Metric Learning for Efficient Aggregation Network</b>,</p>
	                    <p>Yongming Rao, Ji Lin, Jiwen Lu, Jie Zhou,</p>
	                    <p>Jan 2017 - Apr 2017, <i><b>Tsinghua University</b></i>,</p>
	                    <p>We develop an aggregation method that produces few high-quality images from redundant and noisy face videos. By combining adversarial learning and metric learning we make the generated image realistic and discriminative in the feature space, which speeds up the recognition and improves accuracy. </p>
	                </div>
	            </div>
	    		
	            <div class="media">
	                <span class="pull-left"><br /><a href="images/cadl.png" class="image"><img src="images/cadl.png" width="96px" alt="" /></a></span>
	                <div class="media-body">
	                    <p><b>Consistent-aware Deep Person Re-identification in a Camera Network</b>,</p>
	                    <p><b>Ji Lin</b>, Liangliang Ren, Jiwen Lu, Jianjiang Feng, Jie Zhou,</p>
	                    <p>June 2016 - Nov 2016, <i><b>Tsinghua University</b></i>,</p>
	                    <p>We develop one of the first frameworks to address the inconsistency problem in multi-camera person re-identification. We model multi-camera re-identification as an optimization problem and solve with gradient descent to eliminate inconsistency, which also guides the back-propagation in the training phase. Our methods outperforms state-of-the-arts by large margins on multiple datasets. </p>
	                </div>
	            </div>
	        </section>
            
            <!-- Work -->
            <section  id="work">
	            <h2>Work Experience</h2>
	            <ul>
	                <li><strong><a href="https://www.sensetime.com/">SenseTime Group Limited</a></strong> 
	                    <br> <b>Vision Researcher, Detection Team </b>
	                    <br> Jan 2017 - Apr 2017, Beijing, China
	                    <br>Developed algorithm on semi-supervised face detection, and more efficient training with large-scale dataset. Explored efficient models for object detection. Part of the results were deployed in real products.</br> </li>

                     <li><strong>Google AI China Center</strong> 
                        <br> <b>AI Intern Researcher</b>
                        <br> Feb 2018 - Sept 2018, Beijing, China
                        <br> Design a framework for automatic network compression (pruning and quantization) with reinforcement learning, which is fully automated and scalable to all kinds of network structures. </br> </li>
	            </ul>
        	</section>

    	
    		<!-- Honors -->
            <section id="Honors">
                <h2>Honors and Awards</h2>
        		<!-- <h4>Academic</h4>
                    <ul>
                        <li><strong>Invited presentation at <a href="http://tdam-bjkl.bjtu.edu.cn/mla2017.html">MLA 2017</a></strong> &nbsp 2017
                        <li><strong>Invited presentation at <a href="http://bigeye.au.tsinghua.edu.cn/sidas2017/index.html">IEEE SIDAS 2017</a></strong> &nbsp 2017
                    </ul> -->
                <h4>Fellowships</h4>
                    <ul>
                        <li><strong>Fellowship of <a href="http://www.tuef.tsinghua.edu.cn/column/sp1">Spark Talents Program</a></strong> &nbsp 2016
                            <br>Awarded to the top 50 Tsinghua students, dedicated to scientific and technological innovations</br> </li>
                    </ul>
                <h4>Scholarships</h4>
                    <ul>
                        <li><strong>China National Scholarship</strong> &nbsp 2017
                            <br>Highest level of scholarship set by the government of China.</br> </li>
                        <li><strong>Cai Xiong Scholarship</strong> &nbsp 2017
                            <br>Awarded to students with excellent scientific potential, only 10 students among all undergraduates in Tsinghua University are selected.</br> </li>
                        <li><strong>Annual Academic Excellent Award</strong> &nbsp 2015-2017
                            <br>Awarded to students with excellent academic achievements, top ~5% out of 262 students.</br> </li>
                        <li><strong>Annual Comprehensive Excellent Award</strong> &nbsp 2015-2017
                            <br>Awarded to students with excellent comprehensive performance, top ~5% out of 262 students.</br> </li>
                        <li><strong>Scholarship of Freshmen, Tsinghua University</strong> &nbsp 2014
                            <br>Awarded to top 10 students in College Entrance Exam.</br> </li>
                    </ul>
                <h4>Awards</h4>
                    <ul>
                        <li><strong>1<sup>st</sup> Prize of 17<sup>th</sup> Electronic Design Contest, Tsinghua University</strong> &nbsp 2016
                            <br>Top robotics competition in Tsinghua University. Rank No.1 in 400 entrants. </br> </li>
                        <li><strong>3<sup>nd</sup> Prize of IEEE 2016 Low Power Image Recognition Challenge (LPIRC’16)</strong> &nbsp 2016
                            <br>Aim to discover the best technology in both image recognition and energy conservation</br> </li>
                        <!-- <li><strong>2<sup>nd</sup> Prize in the National Chemistry Olympiad </strong> &nbsp 2013</li>  -->
                    </ul>
            </section>

		<!--
            <section id="Skills">
                <h2>Skills</h2>
                <ul>
                <br><i class="fa fa-code fa-2x fa-fw"></i> &nbsp Python &nbsp C/C++ &nbsp MATLAB &nbsp Java &nbsp Android <br />
                <br><i class="fa fa-wrench fa-2x fa-fw"></i> &nbsp LaTeX &nbsp Caffe &nbsp TensorFlow &nbsp PyTorch <br />
                <br><i class="fa fa-language fa-2x fa-fw"></i> &nbsp Mandarin Chinese (native) &nbsp English (proficiet)
                </ul>
            </section>
        -->

            <!-- Life -->
            <section id="Life">
        	<h2>Life :)</h2>
                I have a life other than writing codes. Here is a partial catalog of what I'm trying today.
                <!--
                Here is a partial catalog of my attempts at becoming more than what I am today. I doubt I will ever succeed totally but I hope I will never stop trying. 
                -->
                <p></p>
                <h4>Photography</h4>
                <p> 
                	I've been long interested in photography for more than two years. Since I bought my first camera in Spring 2015, I've learnt so much in Photography Team of Tsinghua Student Art Troupe. I catch the sparkling moments and beauties in my life with my camera as very precious memories. I do not post too much of my work on the Internet, but you can still find some in the following sites: <br />
	                    <a href="https://www.instagram.com/__tonylin/">[Instagram]</a> &nbsp 
	                    <a href="https://500px.com/to_tonylin"> [500PX] </a> &nbsp 
	                    <a href="https://tuchong.com/519520/"> [TuChong] </a> &nbsp 
            	</p>

                <h4>Piano</h4>
                <p> I've always wanted to pick up some kind of musical instruments. It may not be the proper age to be proficient in piano, but I'll keep trying. </p>

                <h4>Tennis</h4>
                <p> Tennis is my recent favorite sport (still not proficient though). Reach me if you are interested too! </p>
			</section>
    	
        	<!--
          	<h2>Who searched for me!</h2>
            <div id="clustrmaps-widget">
    		  <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=oQ1KwKMwMu6IYuA5fNffQwoGDCui7FZHrx3Dd2G8VDM&cl=ffffff&w=a"></script>
            </div>
        	-->

        	<!-- Footer -->
            
        </section>

        <section id="footer">
			<div class="container">
				<ul class="copyright">
					<li>&copy; Ji Lin 2018</li>
				</ul>
			</div>
		</section>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
